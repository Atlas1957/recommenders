\documentclass[twoside,11pt]{article}

% Any additional packages needed should be included after jmlr2e.
% Note that jmlr2e.sty includes epsfig, amssymb, natbib and graphicx,
% and defines many common macros, such as 'proof' and 'example'.
%
% It also sets the bibliographystyle to plainnat; for more information on
% natbib citation styles, see the natbib documentation, a copy of which
% is archived at http://www.jmlr.org/format/natbib.pdf

\usepackage{jmlr2e}
\usepackage[utf8]{inputenc}
\usepackage{adjustbox}
\usepackage[flushleft]{threeparttable}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}

% Definitions of handy macros can go here

\newcommand{\dataset}{{\cal D}}
\newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}

% Heading arguments are {volume}{year}{pages}{date submitted}{date published}{paper id}{author-full-names}

\jmlrheading{1}{2019}{1-48}{4/00}{10/00}{msrecorepo}{Microsoft Recommender core development team}

% Short headings should be running head and authors last names

\ShortHeadings{Microsoft Recommenders}{Meila and Jordan}
\firstpageno{1}

\begin{document}

\title{Microsoft Recommenders: best practices for building industry-grade recommender system}

\author{\name Andreas Argyriou \email anargyri@microsoft.com \\
  \name Miguel Gonzalez-Fierro \email migonza@microsoft.com \\
  \name Scott Graham \email scgraham@microsoft.com \\
  \name Nikhil Joglekar \email nikhilj@microsoft.com \\
  \name Jun Ki Min \email jumin@microsoft.com \\
  \name Jeremy Reynolds \email jeremr@microsoft.com \\
  \name Tao Wu \email wutao@microsoft.com \\
  \name Le Zhang \email zhle@microsoft.com \\
  \addr Microsoft \\
  One Microsoft Way, USA
}

\editor{editors here}

\maketitle

\begin{abstract}%   <- trailing '%' for backward compatibility of .sty file
  This paper talks about the design and implementation of \verb|Microsoft Recommenders|, which is aimed at providing researchers and developers with best-practices for building  industry-grade recommendation system at scale. Codes and documentation can be found at \url{https://github.com./microsoft/recommenders}. 
\end{abstract}

\begin{keywords}
  artificial intelligence, recommender system, software engineering
\end{keywords}

\section{Introduction}
\verb|Microsoft Recommenders| is an open-source repository created for sharing the best practices in building industry standard recommender system for varieties of application scenarios. The repository aims at helping developers, scientists and researchers to quickly build production-ready recommendation systems as well as to prototype novel ideas using the provided utility functions. The repository is released under MIT license.

In this paper the \verb|Microsoft Recommenders| repository is introduced with its design principles, technologies under the hood, and technical advantage over the existing approaches.

\section{Microsoft Recommenders}
The following sub-sections brief the design thinking of \verb|Microsoft Recommenders|.

\subsection{Principles}
The \verb|Microsoft Recommenders| repository is designed with the following principles.
\begin{enumerate}
\item \emph{The repository covers a wide spectrum of recommender algorithms, including classic methods such as collaborative filtering and factorization machine, as well as more recent deep learning algorithms with enhanced model accuracy, explainability, and scalability.} The wide breadth of recommendation algorithms, as well as the DevOps pipeline that serves as a backbone underneath the codebase, offers convenience to the researchers and developers for trying different algorithms and selecting the optimal one for particular use case. 
\item \emph{The algorithms are implemented and optimized for easy adoption and customization.} It is a common yet challenging task to generalize implementations of various components in a recommender system for development efficiency. The repository provides modular and reusable assets with consistent formats, coding style, and standard APIs, to enable ready-for-use scenarios as well as user-customized solutions in a recommender system. In addition, the theoretical discussion and code implementation are put into Jupyter notebooks to provide interactive experience for the developers and have them quickly understand, implement or customize different recommendation algorithms. When necessary, the notebooks can be conveniently converted to production-ready codes with minimal efforts on refactoring. 
\item \emph{The Recommenders repository supports heterogeneous computing platforms and data storage media that meet the requirements of the different workloads in a recommender system pipeline.} To harness the engineering problems in recommender system development, the repository provides reference architectures that demonstrates how to build an enterprise level end-to-end recommendation system.  
\end{enumerate}

\subsection{Code design}
The major deliverables in the repository are \verb|notebooks| and \verb|reco_utils|. Both are implemented in \verb|Python| which is the most popular programming tool to the contemporary data science and machine learning problems.

\begin{itemize}
 \item \verb|notebooks| are Jupyter notebooks where particular topics like recommender algorithms, data preparation methods, evaluation metrics, etc. are detailed with both text and codes. The advantage of using Jupyter notebook is that it make it convenient to users to interactively walk through the code samples, and to convert to Python scripts if needed.
 \item \verb|reco_utils| are reusable assets for common tasks in building recommender system. Such tasks include data preparation, evaluation, etc. To favor such operations with scalability consideration, some of the \verb|reco_utils| are implemented in both Python and PySpark versions. The API design of the \verb|reco_utils| follows the software engineering principles like "evidence-based design", "single responsibility", etc., to guarantee consistency, simplicity, and modularity.
\end{itemize}
The codebase of both \verb|notebooks| and \verb|reco_utils| are built with unit, integration, and smoke tests to assure their appropriate functionality.

\subsection{Technologies}
\verb|Microsoft Recommenders| supports various platforms for building recommender systems with the cutting-edge recommendation algorithms. Users of the repository can conveniently choose the desired algorithms for implementing on their supported platforms like single-node CPU computer, Spark cluster, or single-node or multi-node computer(s) with GPU device incorporated. These backend platforms are supported with corresponding programming framworks like PySpark, Tensorflow, etc. \citep{abadi2016tensorflow}

 The table below summarizes the recommender algorithms collected in the repository thus far \citep{ke2017lightgbm,wang2018dkn,lian2018xdeepfm,howard2018fastai,he2017neural,salakhutdinov2007restricted,cheng2016wide,diev2015sar,koren2009matrix} The table also shows the technologies used in the implementation and use case scenario of these algorithms. 

\begin{adjustbox}{angle=90}
  \footnotesize
  \begin{threeparttable}
  \caption{List of the collected recommender algorithms and their supported technology platforms}
    \begin{tabular}{|p{5cm}|p{2cm}|p{4cm}|p{6cm}|}
    \hline
    \textbf{Algorithms} & \textbf{Environment} & \textbf{Type} & \textbf{Description} \\
    \hline
    Alternating Least Square & Spark cluster & Collaborative filtering & Matrix factorization algorithm \\
    \hline
    LightGBM/Gradient Boosting Tree & CPU / Spark cluster & Content-based filtering & Gradient Boosting Tree algorithm for fast training and low memory usage in content-based problems \\
    \hline
    Deep knowledge-aware network\textsuperscript{*} & CPU / GPU & Content-based filtering & Deep learning algorithm with knowledge graph enhancement \\
    \hline
    Extreme Deep Factorization Machine (xDeepFM)\textsuperscript{*} & CPU / GPU & Hybrid & Deep learning based algorithm for implicit and explicit feedback with user/item features \\
    \hline
    FastAI Embedding Dot Bias (FAST) & CPU / GPU & Collaborative filtering & General purpose algorithm with embeddings and biases for users and items \\
    \hline
    Neural Collaborative filtering (NCF)\textsuperscript{*} & CPU / GPU & Collaborative filtering & Deep learning algorithm with enhanced performance for implicit feedback \\
    \hline
    Restricted Boltzmann Machines (RBM)\textsuperscript{*} & CPU / GPU & Collaborative filtering & Neural network based algorithm for learning the underlying probability distribution for explicit or implicit feedback \\
    \hline
    Wide and Deep & CPU / GPU & Hybrid & Deep learning algorithm that can memorize feature interactions and generalize user features \\
    \hline
    Riemannian Low-rank Matrix Completion (RLRMC)\textsuperscript{*} & CPU & Collaborative filtering & Matrix factorization algorithm using Riemannian conjugate gradients optimization with small memory consumption. \\
    \hline
    Simple Algorithm for Recommendation (SAR)\textsuperscript{*} & CPU & Collaborative filtering & Similarity-based algorithm for implicit feedback dataset \\
    \hline
    Surprise/Singular Value Decomposition (SVD) & CPU & Collaborative filtering & Matrix factorization algorithm for predicting explicit rating feedback in datasets that are not very large \\
    \hline
    Vowpal Wabbit Family (VW) & CPU (online training) & Content-based filtering & Fast online learning algorithms, great for scenarios where user features / context are constantly changing \\
    \hline
    \end{tabular}
    \begin{tablenotes}
      \scriptsize
      \item Recommender algorithms labelled with "*" indicate that they are implemented natively in the repository.
    \end{tablenotes}
  \end{threeparttable}
\end{adjustbox}

There are a few machine learning and architecture engineering technologies featured in the repository. For instance, hyperparameter tuning plays a vital part in model selection. Intelligent methods for tuning hyper parameters for recommender models, especially those built with deep learning algorithms, are highly desirable. The repository provides the best practices for optimizing model performance with the state-of-the-arts tuning methods like Bayesian optimization, Hyperband, etc. \citep{pelikan1999boa,li2016hyperband} To avail building industry-grade deployable recommender system, the repository demonstrated reference architecture of building scalable recommender system \footnote{The reference architecture is demonstrated on Microsoft Azure cloud platform.}, by using distributed database, scalable container cluster on Kubernetes, etc.

\section{Comparison}
Compared to the existing packages in the open source community, \verb|Microsoft Recommenders|, ...  

\section{Conclusion}
In this paper, we present \verb|Microsoft Recommenders| repository, which provides a wide collection of the classic and advanced recommender algorithms, as well as useful code modules for building enterprise-grade recommender system. The best practices shared in the repository help researchers and developers to build a whole end-to-end recommender system at scale.

% Acknowledgements should go at the end, before appendices and references

\acks{We would like to acknowledge all the contributors to the repository. The complete name list of the contributors can be found \href{https://github.com/microsoft/recommenders/blob/master/AUTHORS.md}{here}}

% Manual newpage inserted to improve layout of sample file - not
% needed in general before appendices/bibliography.

\newpage

\vskip 0.2in
\bibliography{references}

\end{document}
