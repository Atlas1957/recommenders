{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny Criteo Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Settings and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \n",
      "[GCC 7.3.0]\n",
      "GPUs: [{'device_name': 'Tesla K80', 'total_memory': 11441.1875, 'free_memory': 11373.9375}]\n",
      "Sklearn version: 0.20.1\n",
      "\n",
      "LightGBM version: 2.2.1\n",
      "Tensorflow version: 1.12.0\n",
      "Vowpal Wabbit version: 8.1.1\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../../\")\n",
    "import subprocess as sp\n",
    "from tempfile import TemporaryDirectory\n",
    "from time import process_time\n",
    "\n",
    "import category_encoders as ce\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "from reco_utils.common import tf_utils, gpu_utils, plot\n",
    "import reco_utils.dataset.criteo as criteo\n",
    "import reco_utils.recommender.lightgbm.lightgbm_utils as lgb_utils\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"GPUs: {}\".format(gpu_utils.get_gpu_info()))\n",
    "print(\"Sklearn version: {}\".format(sklearn.__version__))\n",
    "print()\n",
    "\n",
    "print(\"LightGBM version: {}\".format(lgb.__version__))\n",
    "print(\"Tensorflow version: {}\".format(tf.VERSION))\n",
    "process = sp.run(['vw', '--version'], stdout=sp.PIPE, universal_newlines=True)\n",
    "print(\"Vowpal Wabbit version: {}\".format(process.stdout.rstrip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = \"sample\"\n",
    "\n",
    "tmpdir = TemporaryDirectory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data Preparation\n",
    "Here we use CSV format as the example data input. Our example data is a sample (about 100 thousand samples) from [Criteo dataset](https://www.kaggle.com/c/criteo-display-ad-challenge). The Criteo dataset is a well-known industry benchmarking dataset for developing CTR prediction models, and it's frequently adopted as evaluation dataset by research papers. The original dataset is too large for a lightweight demo, so we sample a small portion from it as a demo dataset.\n",
    "\n",
    "Specifically, there are 39 columns of features in Criteo, where 13 columns are numerical features (I1-I13) and the other 26 columns are categorical features (C1-C26)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8.58k/8.58k [00:01<00:00, 7.07kKB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>f54016b9</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>07b5194c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>c5c50484</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>9727dd16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>b04e4670</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>60f6221e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>43f13e8b</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>731c3655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8efede7f</td>\n",
       "      <td>3412118d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e587c466</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>3b183c5c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4392.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>74ef3502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6b3a5ca6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>9117a34a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>26b3c7a7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21c9516a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>b34f3128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label   I1   I2    I3    I4      I5    I6    I7   I8     I9  ...       C17  \\\n",
       "0      0  1.0    1   5.0   0.0  1382.0   4.0  15.0  2.0  181.0  ...  e5ba7672   \n",
       "1      0  2.0    0  44.0   1.0   102.0   8.0   2.0  2.0    4.0  ...  07c540c4   \n",
       "2      0  2.0    0   1.0  14.0   767.0  89.0   4.0  2.0  245.0  ...  8efede7f   \n",
       "3      0  NaN  893   NaN   NaN  4392.0   NaN   0.0  0.0    0.0  ...  1e88c74f   \n",
       "4      0  3.0   -1   NaN   0.0     2.0   0.0   3.0  0.0    0.0  ...  1e88c74f   \n",
       "\n",
       "        C18       C19       C20       C21       C22       C23       C24  \\\n",
       "0  f54016b9  21ddcdc9  b1252a9d  07b5194c       NaN  3a171ecb  c5c50484   \n",
       "1  b04e4670  21ddcdc9  5840adea  60f6221e       NaN  3a171ecb  43f13e8b   \n",
       "2  3412118d       NaN       NaN  e587c466  ad3062eb  3a171ecb  3b183c5c   \n",
       "3  74ef3502       NaN       NaN  6b3a5ca6       NaN  3a171ecb  9117a34a   \n",
       "4  26b3c7a7       NaN       NaN  21c9516a       NaN  32c7478e  b34f3128   \n",
       "\n",
       "        C25       C26  \n",
       "0  e8b83407  9727dd16  \n",
       "1  e8b83407  731c3655  \n",
       "2       NaN       NaN  \n",
       "3       NaN       NaN  \n",
       "4       NaN       NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nume_cols = [\"I\" + str(i) for i in range(1, 14)]\n",
    "cate_cols = [\"C\" + str(i) for i in range(1, 27)]\n",
    "label_col = \"Label\"\n",
    "\n",
    "header = [label_col] + nume_cols + cate_cols\n",
    "\n",
    "all_data = criteo.load_pandas_df(size=SIZE, local_cache_path=tmpdir.name, header=header)\n",
    "display(all_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we cut three sets (train_data (first 80%), valid_data (middle 10%) and test_data (last 10%)), cut from the original all data. <br>\n",
    "Notably, considering the Criteo is a kind of time-series streaming data, which is also very common in recommendation scenario, we split the data by its order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to 3 sets    \n",
    "length = len(all_data)\n",
    "train_data = all_data.loc[:0.8*length-1]\n",
    "valid_data = all_data.loc[0.8*length:0.9*length-1]\n",
    "test_data = all_data.loc[0.9*length:]\n",
    "\n",
    "del all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing value handling: mean for numeric, 'unk' for categorical features\n",
    "# for simplicity, treat categorical features as ordinal feature\n",
    "\n",
    "def fill_na(df, c_cols, n_cols, n_col_means=None):\n",
    "    if not n_col_means:\n",
    "        n_col_means = {}\n",
    "        \n",
    "    for item in tqdm(c_cols):\n",
    "        df[item].fillna(\"UNK\", inplace=True)\n",
    "\n",
    "    for item in tqdm(n_cols):\n",
    "        if item not in n_col_means:\n",
    "            n_col_means[item] = df[item].mean()\n",
    "        df[item].fillna(n_col_means[item], inplace=True)\n",
    "    \n",
    "    return n_col_means\n",
    "\n",
    "encoder = ce.ordinal.OrdinalEncoder(cols=cate_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.44it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric column mean values in the training set: {'I1': 3.70451525729157, 'I2': 112.293575, 'I3': 39.578949807667705, 'I4': 8.309818756880512, 'I5': 17539.79811756683, 'I6': 140.47713106394087, 'I7': 14.953125205044286, 'I8': 13.48726740330108, 'I9': 124.50148944267035, 'I10': 0.612250872649441, 'I11': 2.3841056126399383, 'I12': 0.9390330900502435, 'I13': 11.522395696055991}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>44.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>767.0</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.704515</td>\n",
       "      <td>893</td>\n",
       "      <td>39.57895</td>\n",
       "      <td>8.309819</td>\n",
       "      <td>4392.0</td>\n",
       "      <td>140.477131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>39.57895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label        I1   I2        I3         I4      I5          I6    I7   I8  \\\n",
       "0      0  1.000000    1   5.00000   0.000000  1382.0    4.000000  15.0  2.0   \n",
       "1      0  2.000000    0  44.00000   1.000000   102.0    8.000000   2.0  2.0   \n",
       "2      0  2.000000    0   1.00000  14.000000   767.0   89.000000   4.0  2.0   \n",
       "3      0  3.704515  893  39.57895   8.309819  4392.0  140.477131   0.0  0.0   \n",
       "4      0  3.000000   -1  39.57895   0.000000     2.0    0.000000   3.0  0.0   \n",
       "\n",
       "      I9  ...  C17  C18  C19  C20  C21  C22  C23  C24  C25  C26  \n",
       "0  181.0  ...    1    1    1    1    1    1    1    1    1    1  \n",
       "1    4.0  ...    2    2    1    2    2    1    1    2    1    2  \n",
       "2  245.0  ...    3    3    2    3    3    2    1    3    2    3  \n",
       "3    0.0  ...    4    4    2    3    4    1    1    4    2    3  \n",
       "4    0.0  ...    4    5    2    3    5    1    2    5    2    3  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nume_means = fill_na(train_data, cate_cols, nume_cols)\n",
    "\n",
    "print(\"Numeric column mean values in the training set: {}\".format(nume_means))\n",
    "\n",
    "train_data = encoder.fit_transform(train_data)\n",
    "display(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 13.90it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 13.59it/s]\n",
      "100%|██████████| 26/26 [00:01<00:00, 13.89it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 13.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Pass train set's n_col_means\n",
    "fill_na(valid_data, cate_cols, nume_cols, nume_means)\n",
    "valid_data = encoder.transform(valid_data)\n",
    "\n",
    "fill_na(test_data, cate_cols, nume_cols, nume_means)\n",
    "test_data = encoder.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 LightGBM - Parameter Setting\n",
    "Let's set the main related parameters for LightGBM now. Basically, the task is a binary classification (predicting click or no click), so the objective function is set to binary logloss, and 'AUC' metric, is used as a metric which is less effected by imbalance in the classes of the dataset.\n",
    "\n",
    "Generally, we can adjust the number of leaves (MAX_LEAF), the minimum number of data in each leaf (MIN_DATA), maximum number of trees (NUM_OF_TREES), the learning rate of trees (TREE_LEARNING_RATE) and EARLY_STOPPING_ROUNDS (to avoid overfitting) in the model to get better performance.\n",
    "\n",
    "Besides, we can also adjust some other listed parameters to optimize the results. [In this link](https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst), a list of all the parameters is shown. Also, some advice on how to tune these parameters can be found [in this url](https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters-Tuning.rst). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "MAX_LEAF = 64\n",
    "MIN_DATA = 20\n",
    "NUM_OF_TREES = 100\n",
    "TREE_LEARNING_RATE = 0.15\n",
    "EARLY_STOPPING_ROUNDS = 20\n",
    "METRIC = \"auc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': \"binary\",\n",
    "    'metric': METRIC,\n",
    "    'num_leaves': MAX_LEAF,\n",
    "    'min_data': MIN_DATA,\n",
    "    'boost_from_average': True,\n",
    "    'num_threads': 20,           # set it according to your cpu cores\n",
    "    'feature_fraction': 0.8,     # select 80% of features before training each tree\n",
    "    'learning_rate': TREE_LEARNING_RATE,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 LightGBM - Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: X: (80000, 39), Y: (80000,)\n",
      "Valid Data Shape: X: (10000, 39); Y: (10000,)\n",
      "Test Data Shape: X: (10000, 39); Y: (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_x = train_data.copy()\n",
    "train_y = train_x.pop(label_col).values\n",
    "valid_x = valid_data.copy()\n",
    "valid_y = valid_x.pop(label_col).values\n",
    "test_x = test_data.copy()\n",
    "test_y = test_x.pop(label_col).values\n",
    "\n",
    "print(\n",
    "    \"Train Data Shape: X: {trn_x_shape}, Y: {trn_y_shape}\\n\"\n",
    "    \"Valid Data Shape: X: {vld_x_shape}; Y: {vld_y_shape}\\n\"\n",
    "    \"Test Data Shape: X: {tst_x_shape}; Y: {tst_y_shape}\".format(\n",
    "        trn_x_shape=train_x.shape,\n",
    "        trn_y_shape=train_y.shape,\n",
    "        vld_x_shape=valid_x.shape,\n",
    "        vld_y_shape=valid_y.shape,\n",
    "        tst_x_shape=test_x.shape,\n",
    "        tst_y_shape=test_y.shape,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 LightGBM - Create model\n",
    "When both hyper-parameters and data are ready, we can create a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.726354\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\tvalid_0's auc: 0.739955\n",
      "[3]\tvalid_0's auc: 0.745388\n",
      "[4]\tvalid_0's auc: 0.749606\n",
      "[5]\tvalid_0's auc: 0.75325\n",
      "[6]\tvalid_0's auc: 0.755573\n",
      "[7]\tvalid_0's auc: 0.756963\n",
      "[8]\tvalid_0's auc: 0.759945\n",
      "[9]\tvalid_0's auc: 0.760396\n",
      "[10]\tvalid_0's auc: 0.760184\n",
      "[11]\tvalid_0's auc: 0.759827\n",
      "[12]\tvalid_0's auc: 0.760955\n",
      "[13]\tvalid_0's auc: 0.762486\n",
      "[14]\tvalid_0's auc: 0.763425\n",
      "[15]\tvalid_0's auc: 0.763039\n",
      "[16]\tvalid_0's auc: 0.763152\n",
      "[17]\tvalid_0's auc: 0.763261\n",
      "[18]\tvalid_0's auc: 0.763119\n",
      "[19]\tvalid_0's auc: 0.76278\n",
      "[20]\tvalid_0's auc: 0.762748\n",
      "[21]\tvalid_0's auc: 0.762998\n",
      "[22]\tvalid_0's auc: 0.762733\n",
      "[23]\tvalid_0's auc: 0.76194\n",
      "[24]\tvalid_0's auc: 0.761843\n",
      "[25]\tvalid_0's auc: 0.761785\n",
      "[26]\tvalid_0's auc: 0.761555\n",
      "[27]\tvalid_0's auc: 0.761103\n",
      "[28]\tvalid_0's auc: 0.761141\n",
      "[29]\tvalid_0's auc: 0.760587\n",
      "[30]\tvalid_0's auc: 0.759864\n",
      "[31]\tvalid_0's auc: 0.759586\n",
      "[32]\tvalid_0's auc: 0.759272\n",
      "[33]\tvalid_0's auc: 0.758353\n",
      "[34]\tvalid_0's auc: 0.757997\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.763425\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(\n",
    "    train_x, train_y.reshape(-1), params=params, categorical_feature=cate_cols\n",
    ")\n",
    "lgb_valid = lgb.Dataset(\n",
    "    valid_x, valid_y.reshape(-1), reference=lgb_train, categorical_feature=cate_cols\n",
    ")\n",
    "lgb_test = lgb.Dataset(\n",
    "    test_x, test_y.reshape(-1), reference=lgb_train, categorical_feature=cate_cols\n",
    ")\n",
    "lgb_model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    num_boost_round=NUM_OF_TREES,\n",
    "    early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "    valid_sets=lgb_valid,\n",
    "    categorical_feature=cate_cols,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what is the model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc': 0.7649360450087227, 'logloss': 0.4703181701876848}\n"
     ]
    }
   ],
   "source": [
    "test_preds = lgb_model.predict(test_x)\n",
    "auc = roc_auc_score(np.asarray(test_y.reshape(-1)), np.asarray(test_preds))\n",
    "logloss = log_loss(np.asarray(test_y.reshape(-1)), np.asarray(test_preds), eps=1e-12)\n",
    "res_basic = {\"auc\": auc, \"logloss\": logloss}\n",
    "print(res_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vowpal Wabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(tmpdir.name, 'vw.model')\n",
    "saved_model_path = os.path.join(tmpdir.name, 'vw_saved.model')\n",
    "train_path = os.path.join(tmpdir.name, 'train.dat')\n",
    "test_path = os.path.join(tmpdir.name, 'test.dat')\n",
    "prediction_path = os.path.join(tmpdir.name, 'prediction.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vw(df, l_col, n_cols, c_cols, output_path):\n",
    "    \"\"\"Convert Pandas DataFrame to vw input format\n",
    "    \"\"\"\n",
    "    with open(output_path, \"w\") as f:\n",
    "        tmp = df.reset_index()\n",
    "\n",
    "        # When using logistic or hinge loss, the labels need to be from the set {+1,-1}\n",
    "        tmp[l_col] = tmp[l_col].apply(lambda x: -1 if x == 0 else 1)\n",
    "\n",
    "        # convert each row to VW input format (https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Input-format)\n",
    "        # [label] [tag]|[user namespace] [user id feature] |[item namespace] [movie id feature]\n",
    "        # label is the true rating, tag is a unique id for the example just used to link predictions to truth\n",
    "        # user and item namespaces separate the features to support interaction features through command line options\n",
    "        # Note, space around `|` is very significant and should follow exact rules.\n",
    "        for row in tqdm(tmp.itertuples()):\n",
    "            n_feats = []\n",
    "            for col in n_cols:\n",
    "                n_feats.append(\"|{} {} \".format(col, getattr(row, col)))\n",
    "            c_feats = []\n",
    "            for col in c_cols:\n",
    "                c_feats.append(\"|{} {} \".format(col, getattr(row, col)))\n",
    "            f.write(\n",
    "                \"{:d} {:d}{} {}\".format(\n",
    "                    getattr(row, l_col),\n",
    "                    row.index,\n",
    "                    \"\".join(n_feats).rstrip(),\n",
    "                    \"\".join(c_feats).rstrip(),\n",
    "                )\n",
    "            )\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vw(train_params, test_params, test_df, l_col, prediction_path):\n",
    "    \"\"\"Convenience function to train, test, and show metrics of interest\n",
    "    Args:\n",
    "        train_params (str): vw training parameters\n",
    "        test_params (str): vw testing parameters\n",
    "        test_data (pd.DataFrame):\n",
    "        l_col (str): label column name\n",
    "        prediction_path (str): path to vw prediction output\n",
    "    Returns:\n",
    "        (dict): metrics and timing information\n",
    "    \"\"\"\n",
    "    # train model\n",
    "    train_start = process_time()\n",
    "    sp.run(train_params.split(' '), check=True)\n",
    "    train_stop = process_time()\n",
    "    \n",
    "    # test model\n",
    "    test_start = process_time()\n",
    "    sp.run(test_params.split(' '), check=True)\n",
    "    test_stop = process_time()\n",
    "    \n",
    "    # read in predictions\n",
    "    pred_df = pd.read_csv(prediction_path, delim_whitespace=True, names=['prediction'], index_col=1).join(test_df)\n",
    "    test_y = pred_df.pop(l_col).values\n",
    "    test_preds = pred_df['prediction'].values\n",
    "    \n",
    "    # calculate metrics\n",
    "    result = dict()\n",
    "    result['auc'] = roc_auc_score(np.asarray(test_y.reshape(-1)), np.asarray(test_preds))\n",
    "    result['logloss'] = log_loss(np.asarray(test_y.reshape(-1)), np.asarray(test_preds), eps=1e-12)\n",
    "    result['Train Time (ms)'] = (train_stop - train_start) * 1000\n",
    "    result['Test Time (ms)'] = (test_stop - test_start) * 1000\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90000it [00:03, 29619.85it/s]\n",
      "10000it [00:00, 28960.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# save train and test data in vw format\n",
    "to_vw(\n",
    "    # TODO shouldn't I use item id as index????\n",
    "    df=pd.concat([train_data, valid_data]).reset_index(drop=True),\n",
    "    l_col=label_col,\n",
    "    n_cols=nume_cols,\n",
    "    c_cols=cate_cols,\n",
    "    output_path=train_path\n",
    ")\n",
    "to_vw(\n",
    "    df=test_data,\n",
    "    l_col=label_col,\n",
    "    n_cols=nume_cols,\n",
    "    c_cols=cate_cols,    \n",
    "    output_path=test_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = \"vw --loss_function logistic -f {model} -d {data} --quiet\".format(\n",
    "    model=model_path, data=train_path\n",
    ")\n",
    "test_params = \"vw --link logistic -i {model} -d {data} -t -p {pred} --quiet\".format(\n",
    "    model=model_path, data=test_path, pred=prediction_path\n",
    ")\n",
    "\n",
    "# train model\n",
    "train_start = process_time()\n",
    "sp.run(train_params.split(' '), check=True)\n",
    "train_stop = process_time()\n",
    "\n",
    "# test model\n",
    "test_start = process_time()\n",
    "sp.run(test_params.split(' '), check=True)\n",
    "test_stop = process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.7705353921278044,\n",
       " 'logloss': 0.46926060131459496,\n",
       " 'Train Time (ms)': 7.8346579999930555,\n",
       " 'Test Time (ms)': 6.585210000011443}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = run_vw(\n",
    "    train_params=train_params,\n",
    "    test_params=test_params,\n",
    "    test_df=test_data,\n",
    "    l_col=label_col,\n",
    "    prediction_path=prediction_path\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpy1v7u5kv/prediction.dat'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "reco_gpu",
   "language": "python",
   "name": "reco_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
