{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.<br>\n",
    "Licensed under the MIT License.</i>\n",
    "<br><br>\n",
    "# SVD Hyperparameter Tuning with Kubeflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show how to tune the hyperparameters of a matrix factorization algorithm, SVD (Singular Value Decomposition) from the Surprise library, by utilizing **[Kubeflow](https://www.kubeflow.org/)** in the context of movie recommendations. Kubeflow is a machine learning toolkit for [Kubernetes](https://kubernetes.io/) which makes deployments of machine learning (ML) workflows on Kubernetes simple, portable and scalable.\n",
    "\n",
    "We present the overall process of deploying Kubeflow on [AKS (Azure Kubernetes Service)](https://azure.microsoft.com/en-us/services/kubernetes-service/) and utilize it to run hyperparameter tuning experiments by demonstrating some key steps while avoiding too much detail. \n",
    "\n",
    "For more details about the **SVD** algorithm:\n",
    "* [Surprise SVD deep-dive notebook](../02_model/surprise_svd_deep_dive.ipynb)\n",
    "* [Original paper](http://papers.nips.cc/paper/3208-probabilistic-matrix-factorization.pdf)\n",
    "* [Surprise homepage](https://surprise.readthedocs.io/en/stable/)\n",
    "  \n",
    "Regarding **Kubeflow**, please refer to:\n",
    "* [Azure Kubeflow labs github repo](https://github.com/Azure/kubeflow-labs)\n",
    "* [Kubeflow official doc: Getting started on Kubernetes](https://www.kubeflow.org/docs/started/getting-started-k8s/)\n",
    "* [Hyperparameter tuning a Tensorflow model on Kubeflow with GPU cluster](https://github.com/loomlike/hyperparameter-tuning-on-kubernetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prerequisites\n",
    "\n",
    "* Docker (if you want to create your own docker image) - To install, see [docker site](https://docs.docker.com/install/).\n",
    "* Azure CLI - The easiest way is to use [Azure DSVM](https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/).\n",
    "  - You need the Azure CLI version 2.0.64 or later installed and configured. Run `az --version` to find the version. If you need to install or upgrade, see [Install Azure CLI](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli-apt?view=azure-cli-latest#update)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.6.8 |Anaconda, Inc.| (default, Dec 29 2018, 19:04:46) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "Surprise version: 1.0.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import time\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import surprise\n",
    "import papermill as pm\n",
    "import pandas as pd\n",
    "\n",
    "from reco_utils.common.constants import SEED\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.python_splitters import python_random_split\n",
    "from reco_utils.evaluation.python_evaluation import rmse, precision_at_k, ndcg_at_k\n",
    "from reco_utils.recommender.surprise.surprise_utils import compute_rating_predictions, compute_ranking_predictions\n",
    "from reco_utils.kubeflow.manifest.utils import (\n",
    "    choice,\n",
    "    uniform,\n",
    "    make_hypertune_manifest,\n",
    "    worker_manifest,\n",
    ")\n",
    "from reco_utils.kubeflow.manifest import (\n",
    "    Goal,\n",
    "    SearchType,\n",
    "    WorkerType,\n",
    ")\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Surprise version: {}\".format(surprise.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "During the setup, we create AKS cluster and install Kubeflow on it.\n",
    "\n",
    "#### 1.1 AKS setup\n",
    "To create AKS and cluster, first make sure you signed in to use Azure CLI with a correct subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az account show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the subscription, run `az account set --subscription <YOUR-SUBSCRIPTION-NAME-OR-ID>`.\n",
    "\n",
    "Next, **set desired names for your resource group and AKS as well as the region you want to create the resources at** to the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RG_NAME = \"reco-aks-rg\"  # YOUR-RESOURCE-GROUP-NAME\n",
    "AKS_NAME = \"reco-aks\"    # RESOURCE-NAME\n",
    "LOCATION = \"eastus\"      # RESOURCE-REGION. To get all the available region, run 'az account list-locations' and see 'name' key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, run the following commands to create the resources. This example will create four [Standard_D2_v2](https://docs.microsoft.com/en-us/azure/virtual-machines/linux/sizes-general#dv2-series) CPU VM nodes for the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create resource group\n",
    "!az group create --name {RG_NAME} --location {LOCATION}\n",
    "\n",
    "# Create AKS cluster\n",
    "!az aks create \\\n",
    "    --resource-group {RG_NAME} \\\n",
    "    --name {AKS_NAME} \\\n",
    "    --node-count 4 \\\n",
    "    --node-vm-size Standard_D2_v2 \\\n",
    "    --enable-addons monitoring \\\n",
    "    --generate-ssh-keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an AKS cluster may take few minutes. If the creation is successful, you'll see something like:\n",
    "```\n",
    "{- Finished ..ion done[############################################]  100.0000%\n",
    "  \"aadProfile\": null,\n",
    "    \"addonProfiles\": {\n",
    "      \"omsagent\": {\n",
    "        \"config\": {\n",
    "  ...\n",
    "```\n",
    "\n",
    "Now, install [Kubernetes CLI](https://docs.microsoft.com/en-us/azure/aks/tutorial-kubernetes-deploy-cluster#install-the-kubernetes-cli) `kubectl` for running commands against the cluster. If you already installed kubectl, skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az aks install-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect the CLI to your cluster by runing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az aks get-credentials --resource-group {RG_NAME} --name {AKS_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have an error, check if you have read/write permissions on the kubernetes config file. In a linux machine, the file will be at `~/.kube/config`.\n",
    "\n",
    "To verify the connection of CLI to your cluster, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       STATUS   ROLES   AGE   VERSION\n",
      "aks-nodepool1-30917087-0   Ready    agent   23h   v1.12.8\n",
      "aks-nodepool1-30917087-1   Ready    agent   23h   v1.12.8\n",
      "aks-nodepool1-30917087-2   Ready    agent   23h   v1.12.8\n",
      "aks-nodepool1-30917087-3   Ready    agent   23h   v1.12.8\n"
     ]
    }
   ],
   "source": [
    "!kubectl get nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the connection is successful, the nodes information will be printed out like:\n",
    "```\n",
    "NAME                       STATUS    ROLES     AGE       VERSION\n",
    "aks-nodepool1-17965807-0   Ready     agent     11m       v1.12.8\n",
    "...\n",
    "```\n",
    "\n",
    "#### 1.2 Kubeflow setup\n",
    "Kubeflow makes use of *[ksonnet](https://www.kubeflow.org/docs/components/ksonnet/)* to help manage deployments.\n",
    "\n",
    "First, setup environment variables and download the ksonnet file by running the following scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OS_TYPE\"] = \"linux\"  # Use \"darwin\" for Mac\n",
    "os.environ[\"KS_VER\"] = \"0.13.1\"\n",
    "os.environ[\"KS_PKG\"] = \"ks_{0}_{1}_amd64\".format(os.environ[\"KS_VER\"], os.environ[\"OS_TYPE\"])\n",
    "os.environ[\"PATH\"] = \"{0}:{1}/bin/{2}\".format(\n",
    "    os.environ[\"PATH\"],\n",
    "    os.environ[\"HOME\"],\n",
    "    os.environ[\"KS_PKG\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x ks_0.13.1_darwin_amd64/CHANGELOG.md\n",
      "x ks_0.13.1_darwin_amd64/CODE-OF-CONDUCT.md\n",
      "x ks_0.13.1_darwin_amd64/CONTRIBUTING.md\n",
      "x ks_0.13.1_darwin_amd64/LICENSE\n",
      "x ks_0.13.1_darwin_amd64/README.md\n",
      "x ks_0.13.1_darwin_amd64/ks\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "wget -O /tmp/${KS_PKG}.tar.gz https://github.com/ksonnet/ksonnet/releases/download/v${KS_VER}/${KS_PKG}.tar.gz -q\n",
    "mkdir -p ${HOME}/bin\n",
    "tar -xvf /tmp/${KS_PKG}.tar.gz -C ${HOME}/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, download, extract Kubeflow and deploy it. For more details about this process, please see [installation instruction of Kubeflow on Azure](https://www.kubeflow.org/docs/azure/deploy/install-kubeflow/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KFCTL_VER\"] = \"0.5.1\"\n",
    "os.environ[\"KFCTL_PKG\"] = \"kfctl_v{}_{}\".format(os.environ[\"KFCTL_VER\"], os.environ[\"OS_TYPE\"])\n",
    "os.environ[\"PATH\"] = \"{0}:{1}/bin\".format(\n",
    "    os.environ[\"PATH\"],\n",
    "    os.environ[\"HOME\"]\n",
    ")\n",
    "os.environ['KFAPP'] = \"kfapp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x ./kfctl\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "wget -O /tmp/${KFCTL_PKG}.tar.gz https://github.com/kubeflow/kubeflow/releases/download/v${KFCTL_VER}/${KFCTL_PKG}.tar.gz -q\n",
    "tar -xvf /tmp/${KFCTL_PKG}.tar.gz -C ${HOME}/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "kfctl init ${KFAPP}\n",
    "cd ${KFAPP}\n",
    "kfctl generate k8s\n",
    "kfctl apply k8s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the deployment, check kubeflow pods as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                       READY   STATUS    RESTARTS   AGE\n",
      "ambassador-7b8477f667-96mmt                                1/1     Running   0          21h\n",
      "ambassador-7b8477f667-kbchr                                1/1     Running   0          21h\n",
      "ambassador-7b8477f667-mswcr                                1/1     Running   0          21h\n",
      "argo-ui-9cbd45fdf-sgm6k                                    1/1     Running   0          21h\n",
      "centraldashboard-796c755dcf-v6ctn                          1/1     Running   0          21h\n",
      "jupyter-web-app-589f8756c9-rvvlx                           1/1     Running   0          21h\n",
      "katib-ui-7c6997fd96-rqkdw                                  1/1     Running   0          21h\n",
      "metacontroller-0                                           1/1     Running   0          21h\n",
      "minio-594df758b9-sqnfc                                     1/1     Running   0          21h\n",
      "ml-pipeline-75b5d4585-dqwzb                                1/1     Running   0          21h\n",
      "ml-pipeline-persistenceagent-7ffd468c4b-blr59              1/1     Running   0          21h\n",
      "ml-pipeline-scheduledworkflow-56c8f5bc9b-62kgv             1/1     Running   0          21h\n",
      "ml-pipeline-ui-858f7f979d-7cpk2                            1/1     Running   0          21h\n",
      "ml-pipeline-viewer-controller-deployment-cc7fb8dfd-djrvm   1/1     Running   0          21h\n",
      "mysql-5d5b5475c4-d6n46                                     1/1     Running   0          21h\n",
      "notebooks-controller-685db44f8c-wc2hp                      1/1     Running   0          21h\n",
      "pytorch-operator-9996bcb49-9jpp2                           1/1     Running   0          21h\n",
      "studyjob-controller-57cb6746ff-49d8s                       1/1     Running   0          21h\n",
      "tensorboard-76dffc9ffc-7rhfc                               1/1     Running   0          21h\n",
      "tf-job-dashboard-84bdddd5cc-gmzxk                          1/1     Running   0          21h\n",
      "tf-job-operator-8486555578-922zj                           1/1     Running   0          21h\n",
      "vizier-core-bcc86677d-58xm9                                1/1     Running   2          21h\n",
      "vizier-core-rest-68c7577f84-xp6h2                          1/1     Running   0          21h\n",
      "vizier-db-54f46c46c6-gvqj2                                 1/1     Running   0          21h\n",
      "vizier-suggestion-bayesianoptimization-97f4f76dd-hvbkj     1/1     Running   0          21h\n",
      "vizier-suggestion-grid-6f94f98f9d-5n2qp                    1/1     Running   0          21h\n",
      "vizier-suggestion-hyperband-68f4cc7f5d-7xbm7               1/1     Running   0          21h\n",
      "vizier-suggestion-random-6ff5b8f6d8-9qj5m                  1/1     Running   0          21h\n",
      "workflow-controller-d5cb6468d-zcj5k                        1/1     Running   0          21h\n"
     ]
    }
   ],
   "source": [
    "!kubectl -n kubeflow get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the namespace to be \"kubeflow\" so that we don't need to use `-n kubeflow` argument for every *kubectl* command in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context \"junminaks-cpu\" modified.\n"
     ]
    }
   ],
   "source": [
    "!kubectl config set-context {AKS_NAME} --namespace=kubeflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Persistent volumn setup\n",
    "One last thing we should do before moving to the next step is to create a persistent volumn to store our dataset. A PersistentVolumeClaim (PVC) is a request for storage by a user. For details, see [persistent volumes with Azure files](https://docs.microsoft.com/en-us/azure/aks/azure-files-dynamic-pv). Here, we create 10G size storage, which is defined in *[reco_utils/kubeflow/manifest/azure-file-pvc.yaml](../../reco_utils/kubeflow/manifest/azure-file-pvc.yaml)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storageclass.storage.k8s.io/azurefile created\n",
      "clusterrole.rbac.authorization.k8s.io/system:azure-cloud-provider created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/system:azure-cloud-provider created\n",
      "persistentvolumeclaim/azurefile created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f ../../reco_utils/kubeflow/manifest/azure-file-sc.yaml\n",
    "!kubectl apply -f ../../reco_utils/kubeflow/manifest/azure-pvc-roles.yaml\n",
    "!kubectl apply -f ../../reco_utils/kubeflow/manifest/azure-file-pvc.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the deployment, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME        STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n",
      "azurefile   Bound    pvc-3086e6ad-8e16-11e9-9ec7-46b2371e9153   10Gi       RWX            azurefile      20h\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pvc azurefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experiment Preparation\n",
    "#### 2.1 Dataset\n",
    "1. Download data and split into training, validation and testing sets\n",
    "2. Upload the training and validation sets to our PVC. To do that,\n",
    "  1. Attach a pod to the PVC\n",
    "  2. Copy the datasets onto the pod\n",
    "  3. Delete the pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'\n",
    "\n",
    "TRAIN_FILE_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_train.pkl\"\n",
    "VAL_FILE_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_val.pkl\"\n",
    "TEST_FILE_NAME = \"movielens_\" + MOVIELENS_DATA_SIZE + \"_test.pkl\"\n",
    "\n",
    "USERCOL = 'userID'\n",
    "ITEMCOL = 'itemID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.81k/4.81k [00:00<00:00, 5.14kKB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  rating\n",
       "0     196     242     3.0\n",
       "1     186     302     3.0\n",
       "2      22     377     1.0\n",
       "3     244      51     2.0\n",
       "4     166     346     1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = movielens.load_pandas_df(\n",
    "    size=MOVIELENS_DATA_SIZE,\n",
    "    header=[USERCOL, ITEMCOL, \"rating\"]\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test = python_random_split(data, [0.7, 0.15, 0.15], seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir = TemporaryDirectory()\n",
    "\n",
    "train_pickle_path = os.path.join(tmpdir.name, TRAIN_FILE_NAME)\n",
    "train.to_pickle(train_pickle_path)\n",
    "\n",
    "val_pickle_path = os.path.join(tmpdir.name, VAL_FILE_NAME)\n",
    "validation.to_pickle(val_pickle_path)\n",
    "\n",
    "test_pickle_path = os.path.join(tmpdir.name, TEST_FILE_NAME)\n",
    "test.to_pickle(test_pickle_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a pod by using [reco_utils/kubeflow/manifest/pvc-loader.yaml](../../reco_utils/kubeflow/manifest/pvc-loader.yaml) to upload the datasets into `/data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod \"pvc-loader\" deleted\n",
      "pod/pvc-loader created\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete pod pvc-loader  # Delete if the pod already exists\n",
    "!kubectl apply -f ../../reco_utils/kubeflow/manifest/pvc-loader.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data files\n",
    "!kubectl cp {train_pickle_path} pvc-loader:/data/\n",
    "!kubectl cp {val_pickle_path} pvc-loader:/data/\n",
    "!kubectl cp {test_pickle_path} pvc-loader:/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d5997a7396c4c1db\r\n",
      "fada5d956cce34c3\r\n",
      "movielens_100k_test.pkl\r\n",
      "movielens_100k_train.pkl\r\n",
      "movielens_100k_val.pkl\r\n",
      "sb3123f2df3038dc\r\n"
     ]
    }
   ],
   "source": [
    "# Verify\n",
    "!kubectl exec pvc-loader -- bash -c \"ls /data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After uploading the data, we don't need the pod anymore, so remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod \"pvc-loader\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete pod pvc-loader "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Training scripts\n",
    "\n",
    "We prepare a training script [reco_utils/kubeflow/svd_training.py](../../reco_utils/kubeflow/svd_training.py) for the hyperparameter tuning, which will log our target metrics such as [RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation) and/or [NDCG](https://en.wikipedia.org/wiki/Discounted_cumulative_gain) to Katib so that we can track the metrics and optimize the primary metric.\n",
    "\n",
    "We use the Docker image containing our Recommender repo as well as the training script. For more details, see [reco_utils/kubeflow/docker/Dockerfile](../../reco_utils/kubeflow/docker/Dockerfile).\n",
    "\n",
    "#### 2.3 Parameters\n",
    "\n",
    "We define a search space for the hyperparameters. All the parameter values will be passed into our training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"movielens-\" + MOVIELENS_DATA_SIZE + \"-svd\"\n",
    "PRIMARY_METRIC = 'precision_at_k'\n",
    "PRIMARY_METRIC_GOAL = Goal.MAXIMIZE\n",
    "IDEAL_METRIC_VALUE = 1.0\n",
    "RATING_METRICS = ['rmse']\n",
    "RANKING_METRICS = ['precision_at_k', 'ndcg_at_k']  \n",
    "\n",
    "REMOVE_SEEN = True\n",
    "K = 10\n",
    "RANDOM_STATE = 0\n",
    "VERBOSE = True\n",
    "NUM_EPOCHS = 30\n",
    "BIASED = True\n",
    "\n",
    "MAX_TOTAL_RUNS = 8  # TODO 100 Number of runs (training-and-evaluation) to search for the best hyperparameters. \n",
    "MAX_CONCURRENT_RUNS = 8\n",
    "\n",
    "# PVC mount path\n",
    "STORAGE_MOUNT_PATH = \"/data\"\n",
    "\n",
    "script_params = {\n",
    "    '--datastore': STORAGE_MOUNT_PATH,\n",
    "    '--train-datapath': TRAIN_FILE_NAME,\n",
    "    '--validation-datapath': VAL_FILE_NAME,\n",
    "    '--output-dir': \"outputs\",\n",
    "    '--surprise-reader': \"ml-100k\",\n",
    "    '--rating-metrics': RATING_METRICS,\n",
    "    '--ranking-metrics': RANKING_METRICS,\n",
    "    '--usercol': USERCOL,\n",
    "    '--itemcol': ITEMCOL,\n",
    "    '--k': K,\n",
    "    '--random-state': RANDOM_STATE,\n",
    "    '--epochs': NUM_EPOCHS,\n",
    "}\n",
    "\n",
    "if BIASED:\n",
    "    script_params['--biased'] = ''\n",
    "if VERBOSE:\n",
    "    script_params['--verbose'] = ''\n",
    "if REMOVE_SEEN:\n",
    "    script_params['--remove-seen'] = ''\n",
    "\n",
    "# hyperparameters search space\n",
    "# We do not set 'lr_all' and 'reg_all' because they will be overwritten by the other lr_ and reg_ parameters\n",
    "hyperparams = {\n",
    "    '--n-factors': choice([10, 50, 100, 150, 200]),\n",
    "    '--init-mean': uniform(-0.5, 0.5),\n",
    "    '--init-std-dev': uniform(0.01, 0.2),\n",
    "    '--lr-bu': uniform(1e-6, 0.1), \n",
    "    '--lr-bi': uniform(1e-6, 0.1), \n",
    "    '--lr-pu': uniform(1e-6, 0.1), \n",
    "    '--lr-qi': uniform(1e-6, 0.1), \n",
    "    '--reg-bu': uniform(1e-6, 1),\n",
    "    '--reg-bi': uniform(1e-6, 1), \n",
    "    '--reg-pu': uniform(1e-6, 1), \n",
    "    '--reg-qi': uniform(1e-6, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create worker and study manifests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StudyJob manifest has been generated.        To start, run 'kubectl create -f jobs/movielens-100k-svd-random-1.yaml'\n"
     ]
    }
   ],
   "source": [
    "worker_spec = worker_manifest(\n",
    "    worker_type=WorkerType.WORKER,\n",
    "    image_name='loomlike/reco',\n",
    "    entry_script='/app/reco_utils/kubeflow/svd_training.py',\n",
    "    params=script_params,\n",
    "    is_hypertune=True,\n",
    "    storage_path=STORAGE_MOUNT_PATH,\n",
    "    use_gpu=False,\n",
    ")\n",
    "\n",
    "studyjob_name, studyjob_file = make_hypertune_manifest(\n",
    "    study_name=EXP_NAME,\n",
    "    tag=\"random-1\",\n",
    "    search_type=SearchType.RANDOM,\n",
    "    total_runs=MAX_TOTAL_RUNS,\n",
    "    concurrent_runs=MAX_CONCURRENT_RUNS,\n",
    "    primary_metric=PRIMARY_METRIC,\n",
    "    goal=PRIMARY_METRIC_GOAL,\n",
    "    ideal_metric_value=IDEAL_METRIC_VALUE,\n",
    "    metrics=RATING_METRICS+RANKING_METRICS,\n",
    "    hyperparams=hyperparams,\n",
    "    worker_spec=worker_spec\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studyjob.kubeflow.org \"movielens-100k-svd-random-1\" deleted\n",
      "studyjob.kubeflow.org/movielens-100k-svd-random-1 created\n"
     ]
    }
   ],
   "source": [
    "# Delete previous StudyJob of the same name if exists\n",
    "!kubectl delete studyjob {studyjob_name}\n",
    "\n",
    "# Create a StudyJob\n",
    "!kubectl create -f {studyjob_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:         movielens-100k-svd-random-1\r\n",
      "Namespace:    kubeflow\r\n",
      "Labels:       controller-tools.k8s.io=1.0\r\n",
      "Annotations:  <none>\r\n",
      "API Version:  kubeflow.org/v1alpha1\r\n",
      "Kind:         StudyJob\r\n",
      "Metadata:\r\n",
      "  Creation Timestamp:  2019-06-16T03:41:24Z\r\n",
      "  Finalizers:\r\n",
      "    clean-studyjob-data\r\n",
      "  Generation:        1\r\n",
      "  Resource Version:  461385\r\n",
      "  Self Link:         /apis/kubeflow.org/v1alpha1/namespaces/kubeflow/studyjobs/movielens-100k-svd-random-1\r\n",
      "  UID:               9d4ed7c8-8fe8-11e9-83b5-32708d49e78a\r\n",
      "Spec:\r\n",
      "  Metricsnames:\r\n",
      "    rmse\r\n",
      "    precision_at_k\r\n",
      "    ndcg_at_k\r\n",
      "  Objectivevaluename:  precision_at_k\r\n",
      "  Optimizationgoal:    1\r\n",
      "  Optimizationtype:    maximize\r\n",
      "  Owner:               crd\r\n",
      "  Parameterconfigs:\r\n",
      "    Feasible:\r\n",
      "      List:\r\n",
      "        10\r\n",
      "        50\r\n",
      "        100\r\n",
      "        150\r\n",
      "        200\r\n",
      "    Name:           --n-factors\r\n",
      "    Parametertype:  categorical\r\n",
      "    Feasible:\r\n",
      "      Max:          0.5\r\n",
      "      Min:          -0.5\r\n",
      "    Name:           --init-mean\r\n",
      "    Parametertype:  double\r\n",
      "    Feasible:\r\n",
      "      Max:          0.2\r\n",
      "      Min:          0.01\r\n",
      "    Name:           --init-std-dev\r\n",
      "    Parametertype:  double\r\n",
      "    Feasible:\r\n",
      "      Max:          0.1\r\n",
      "      Min:          1e-06\r\n",
      "    Name:           --lr-bu\r\n",
      "    Parametertype:  double\r\n",
      "    Feasible:\r\n",
      "      Max:          0.1\r\n",
      "      Min:          1e-06\r\n",
      "    Name:           --lr-bi\r\n",
      "    Parametertype:  double\r\n",
      "    Feasible:\r\n",
      "      Max:          0.1\r\n",
      "      Min:          1e-06\r\n",
      "    Name:           --lr-pu\r\n",
      "    Parametertype:  double\r\n",
      "    Feasible:\r\n",
      "      Max:          0.1\r\n",
      "      Min:          1e-06\r\n",
      "    Name:           --lr-qi\r\n",
      "    Parametertype:  double\r\n",
      "    Feasible:\r\n",
      "      Max:          1\r\n",
      "      Min:          1e-06\r\n",
      "    Name:           --reg-bu\r\n",
      "    Parametertype:  double\r\n",
      "    Feasible:\r\n",
      "      Max:          1\r\n",
      "      Min:          1e-06\r\n",
      "    Name:           --reg-bi\r\n",
      "    Parametertype:  double\r\n",
      "    Feasible:\r\n",
      "      Max:          1\r\n",
      "      Min:          1e-06\r\n",
      "    Name:           --reg-pu\r\n",
      "    Parametertype:  double\r\n",
      "    Feasible:\r\n",
      "      Max:          1\r\n",
      "      Min:          1e-06\r\n",
      "    Name:           --reg-qi\r\n",
      "    Parametertype:  double\r\n",
      "  Requestcount:     1\r\n",
      "  Study Name:       movielens-100k-svd-random-1\r\n",
      "  Suggestion Spec:\r\n",
      "    Request Number:        8\r\n",
      "    Suggestion Algorithm:  random\r\n",
      "    Suggestion Parameters:\r\n",
      "      Name:   SuggestionCount\r\n",
      "      Value:  0\r\n",
      "  Worker Spec:\r\n",
      "    Go Template:\r\n",
      "      Raw Template:  apiVersion: batch/v1\r\n",
      "kind: Job\r\n",
      "metadata:\r\n",
      "  name: {{.WorkerID}}\r\n",
      "  namespace: kubeflow\r\n",
      "spec:\r\n",
      "  template:\r\n",
      "    spec:\r\n",
      "      containers:\r\n",
      "      - name: {{.WorkerID}}\r\n",
      "        image: loomlike/reco\r\n",
      "        imagePullPolicy: Always\r\n",
      "        command:\r\n",
      "        - \"python\"\r\n",
      "        - \"/app/reco_utils/kubeflow/svd_training.py\"\r\n",
      "        - \"--datastore=/data\"\r\n",
      "        - \"--train-datapath=movielens_100k_train.pkl\"\r\n",
      "        - \"--validation-datapath=movielens_100k_val.pkl\"\r\n",
      "        - \"--output-dir=outputs\"\r\n",
      "        - \"--surprise-reader=ml-100k\"\r\n",
      "        - \"--rating-metrics\"\r\n",
      "        - \"rmse\"\r\n",
      "        - \"--ranking-metrics\"\r\n",
      "        - \"precision_at_k\"\r\n",
      "        - \"ndcg_at_k\"\r\n",
      "        - \"--usercol=userID\"\r\n",
      "        - \"--itemcol=itemID\"\r\n",
      "        - \"--k=10\"\r\n",
      "        - \"--random-state=0\"\r\n",
      "        - \"--epochs=30\"\r\n",
      "        - \"--biased\"\r\n",
      "        - \"--verbose\"\r\n",
      "        - \"--remove-seen\"\r\n",
      "        {{- with .HyperParameters}}\r\n",
      "        {{- range .}}\r\n",
      "        - \"{{.Name}}={{.Value}}\"\r\n",
      "        {{- end}}\r\n",
      "        {{- end}}\r\n",
      "        volumeMounts:\r\n",
      "          - name: azurefile\r\n",
      "            subPath: {{.StudyID}}\r\n",
      "            mountPath: /data\r\n",
      "      restartPolicy: Never\r\n",
      "      volumes:\r\n",
      "        - name: azurefile\r\n",
      "          persistentVolumeClaim:\r\n",
      "            claimName: azurefile\r\n",
      "Status:\r\n",
      "  Completion Time:          2019-06-16T03:41:44Z\r\n",
      "  Condition:                Completed\r\n",
      "  Last Reconcile Time:      2019-06-16T03:41:44Z\r\n",
      "  Start Time:               2019-06-16T03:41:24Z\r\n",
      "  Studyid:                  oa488f3016a2f640\r\n",
      "  Suggestion Count:         1\r\n",
      "  Suggestion Parameter Id:  mddc785c5ae9bc7c\r\n",
      "  Trials:\r\n",
      "    Trialid:  e722de2b80a577d1\r\n",
      "    Workeridlist:\r\n",
      "      Completion Time:  <nil>\r\n",
      "      Condition:        Failed\r\n",
      "      Kind:             Job\r\n",
      "      Start Time:       2019-06-16T03:41:26Z\r\n",
      "      Workerid:         n6713daa6080e69e\r\n",
      "    Trialid:            a4019df1ed23355d\r\n",
      "    Workeridlist:\r\n",
      "      Completion Time:  <nil>\r\n",
      "      Condition:        Failed\r\n",
      "      Kind:             Job\r\n",
      "      Start Time:       2019-06-16T03:41:26Z\r\n",
      "      Workerid:         ve4dcbdb43cd4602\r\n",
      "    Trialid:            y726de0dae46a5a0\r\n",
      "    Workeridlist:\r\n",
      "      Completion Time:  <nil>\r\n",
      "      Condition:        Failed\r\n",
      "      Kind:             Job\r\n",
      "      Start Time:       2019-06-16T03:41:26Z\r\n",
      "      Workerid:         dc5f268fd43747ce\r\n",
      "    Trialid:            xdc69e791c479155\r\n",
      "    Workeridlist:\r\n",
      "      Completion Time:  <nil>\r\n",
      "      Condition:        Failed\r\n",
      "      Kind:             Job\r\n",
      "      Start Time:       2019-06-16T03:41:26Z\r\n",
      "      Workerid:         a849202b171feacf\r\n",
      "    Trialid:            g88ed3757b77fd45\r\n",
      "    Workeridlist:\r\n",
      "      Completion Time:  <nil>\r\n",
      "      Condition:        Failed\r\n",
      "      Kind:             Job\r\n",
      "      Start Time:       2019-06-16T03:41:26Z\r\n",
      "      Workerid:         o1cd7841a7c706cb\r\n",
      "    Trialid:            u09199617a79d02d\r\n",
      "    Workeridlist:\r\n",
      "      Completion Time:  <nil>\r\n",
      "      Condition:        Failed\r\n",
      "      Kind:             Job\r\n",
      "      Start Time:       2019-06-16T03:41:26Z\r\n",
      "      Workerid:         rb9b2cc6c9f6b77c\r\n",
      "    Trialid:            h56c40d8b57038d1\r\n",
      "    Workeridlist:\r\n",
      "      Completion Time:  <nil>\r\n",
      "      Condition:        Failed\r\n",
      "      Kind:             Job\r\n",
      "      Start Time:       2019-06-16T03:41:26Z\r\n",
      "      Workerid:         y3e6bb29fcaad8fd\r\n",
      "    Trialid:            ec52c528134d0e50\r\n",
      "    Workeridlist:\r\n",
      "      Completion Time:  <nil>\r\n",
      "      Condition:        Failed\r\n",
      "      Kind:             Job\r\n",
      "      Start Time:       2019-06-16T03:41:26Z\r\n",
      "      Workerid:         g9f11e2936e8db9b\r\n",
      "Events:                 <none>\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe studyjob {studyjob_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                       READY   STATUS        RESTARTS   AGE\n",
      "ad37cfbb9d1307a9-1560645420-fncjh                          0/1     Completed     0          18m\n",
      "ad37cfbb9d1307a9-1560645480-gt6fm                          0/1     Error         0          16m\n",
      "adf1589fe7e7f510-1560646380-4j7ps                          0/1     Error         0          2m2s\n",
      "ambassador-7b8477f667-96mmt                                1/1     Running       0          2d5h\n",
      "ambassador-7b8477f667-kbchr                                1/1     Running       0          2d5h\n",
      "ambassador-7b8477f667-mswcr                                1/1     Running       0          2d5h\n",
      "argo-ui-9cbd45fdf-sgm6k                                    1/1     Running       0          2d5h\n",
      "b4148ba65f097977-1560646380-bksm7                          0/1     Error         0          2m2s\n",
      "b43384de369facca-1560646380-blmpz                          0/1     Error         0          2m2s\n",
      "c78adcbe3fc9f484-1560645360-8nslb                          0/1     Error         0          18m\n",
      "c78adcbe3fc9f484-1560645420-zbj79                          0/1     Completed     0          18m\n",
      "c78adcbe3fc9f484-1560645480-g69c9                          0/1     Error         0          16m\n",
      "c7f127697375fcfa-1560618360-bspd6                          0/1     Error         0          7h49m\n",
      "c7f127697375fcfa-1560618420-54zrk                          0/1     Error         0          7h47m\n",
      "c7f127697375fcfa-1560618480-wjfd4                          0/1     Error         0          7h46m\n",
      "centraldashboard-796c755dcf-v6ctn                          1/1     Running       0          2d5h\n",
      "f806a73c4d7b770a-1560646380-69kml                          0/1     Error         0          2m2s\n",
      "h86a057e9e707d15-1560618360-mk8n6                          0/1     Error         0          7h49m\n",
      "h86a057e9e707d15-1560618420-crzp7                          0/1     Error         0          7h47m\n",
      "h86a057e9e707d15-1560618480-765n6                          0/1     Error         0          7h46m\n",
      "h86a057e9e707d15-1560618540-skv2b                          0/1     Error         0          7h45m\n",
      "i313715287f39f60-1560618720-qwpcw                          0/1     Completed     0          7h43m\n",
      "i57e04142fb5c123-1560618720-7hb2f                          0/1     Completed     0          7h43m\n",
      "j67027dbde9a5528-1560646380-2w72r                          0/1     Error         0          2m2s\n",
      "jupyter-web-app-589f8756c9-rvvlx                           1/1     Running       0          2d5h\n",
      "katib-ui-7c6997fd96-rqkdw                                  1/1     Running       0          2d5h\n",
      "l34d92f21610da9b-1560618360-gjtg7                          0/1     Error         0          7h49m\n",
      "l34d92f21610da9b-1560618420-95lwr                          0/1     Error         0          7h47m\n",
      "l34d92f21610da9b-1560618480-qgkst                          0/1     Error         0          7h46m\n",
      "l34d92f21610da9b-1560618540-7bpbg                          0/1     Error         0          7h45m\n",
      "l37aed707695fdb6-1560645360-lbdht                          0/1     Error         0          18m\n",
      "l37aed707695fdb6-1560645420-vrcft                          0/1     Error         0          18m\n",
      "l37aed707695fdb6-1560645480-8p926                          0/1     Error         0          16m\n",
      "l87c08e4e7c18c5f-1560618420-pfdgl                          0/1     Error         0          7h47m\n",
      "l87c08e4e7c18c5f-1560618540-f26lj                          0/1     Error         0          7h45m\n",
      "lb2cd2b68329a5ff-1560618360-2zrzf                          0/1     Completed     0          7h49m\n",
      "lb2cd2b68329a5ff-1560618540-5fvtq                          0/1     Completed     0          7h45m\n",
      "m9bc635898d488b7-1560645360-fs4r2                          0/1     Error         0          18m\n",
      "m9bc635898d488b7-1560645420-vhk8v                          0/1     Error         0          18m\n",
      "m9bc635898d488b7-1560645480-rbt87                          0/1     Completed     0          16m\n",
      "ma2433ec470e69c8-1560645480-5n7sz                          0/1     Error         0          16m\n",
      "metacontroller-0                                           1/1     Running       0          2d5h\n",
      "minio-594df758b9-sqnfc                                     1/1     Running       0          2d5h\n",
      "ml-pipeline-75b5d4585-dqwzb                                1/1     Running       0          2d5h\n",
      "ml-pipeline-persistenceagent-7ffd468c4b-blr59              1/1     Running       0          2d5h\n",
      "ml-pipeline-scheduledworkflow-56c8f5bc9b-62kgv             1/1     Running       0          2d5h\n",
      "ml-pipeline-ui-858f7f979d-7cpk2                            1/1     Running       0          2d5h\n",
      "ml-pipeline-viewer-controller-deployment-cc7fb8dfd-djrvm   1/1     Running       0          2d5h\n",
      "mysql-5d5b5475c4-d6n46                                     1/1     Running       0          2d5h\n",
      "nea2312e10f13dcf-1560645420-rqcsj                          0/1     Error         0          18m\n",
      "nea2312e10f13dcf-1560645480-d24q7                          0/1     Error         0          16m\n",
      "notebooks-controller-685db44f8c-wc2hp                      1/1     Running       0          2d5h\n",
      "o13180cc25c3654e-1560618720-frzw8                          0/1     Completed     0          7h43m\n",
      "o429742980610798-1560618360-s6w5n                          0/1     Error         0          7h49m\n",
      "o429742980610798-1560618420-8xb6s                          0/1     Error         0          7h47m\n",
      "o429742980610798-1560618480-fhzpz                          0/1     Error         0          7h46m\n",
      "o429742980610798-1560618540-hfj74                          0/1     Completed     0          7h45m\n",
      "p1949e2a8a372599-1560618420-mh5pw                          0/1     Error         0          7h47m\n",
      "p1949e2a8a372599-1560618480-jg27x                          0/1     Error         0          7h46m\n",
      "p1949e2a8a372599-1560618540-n48ks                          0/1     Error         0          7h45m\n",
      "pytorch-operator-9996bcb49-9jpp2                           1/1     Running       1          2d5h\n",
      "q9851238fb938d28-1560645360-cd7d8                          0/1     Completed     0          18m\n",
      "q9851238fb938d28-1560645480-h7kwq                          0/1     Error         0          16m\n",
      "rfda38a2dc4a954a-1560646380-zjhxj                          0/1     Error         0          2m2s\n",
      "studyjob-controller-57cb6746ff-49d8s                       1/1     Running       0          2d5h\n",
      "tc8b9300bfcc6fac-1560618480-j5k9h                          0/1     Error         0          7h46m\n",
      "tc8b9300bfcc6fac-1560618540-l9l4q                          0/1     Completed     0          7h45m\n",
      "tensorboard-76dffc9ffc-7rhfc                               1/1     Running       0          2d5h\n",
      "tf-job-dashboard-84bdddd5cc-gmzxk                          1/1     Running       0          2d5h\n",
      "tf-job-operator-8486555578-922zj                           1/1     Running       1          2d5h\n",
      "vizier-core-bcc86677d-58xm9                                1/1     Running       2          2d5h\n",
      "vizier-core-rest-68c7577f84-xp6h2                          1/1     Running       0          2d5h\n",
      "vizier-db-54f46c46c6-gvqj2                                 1/1     Running       0          2d5h\n",
      "vizier-suggestion-bayesianoptimization-97f4f76dd-hvbkj     1/1     Running       0          2d5h\n",
      "vizier-suggestion-grid-6f94f98f9d-5n2qp                    1/1     Running       0          2d5h\n",
      "vizier-suggestion-hyperband-68f4cc7f5d-7xbm7               1/1     Running       0          2d5h\n",
      "vizier-suggestion-random-6ff5b8f6d8-9qj5m                  1/1     Running       0          2d5h\n",
      "workflow-controller-d5cb6468d-zcj5k                        1/1     Running       0          2d5h\n",
      "y401871048048c75-1560645360-xj5mr                          0/1     Error         0          18m\n",
      "y401871048048c75-1560645420-b6s95                          0/1     Completed     0          18m\n",
      "y401871048048c75-1560645480-5hmlj                          0/1     Completed     0          16m\n",
      "y401871048048c75-pf6cs                                     0/1     Terminating   0          16m\n",
      "y4f1762a16a2fb1c-1560646380-b9b9w                          0/1     Error         0          2m1s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:           ad37cfbb9d1307a9-1560645420\r\n",
      "Namespace:      kubeflow\r\n",
      "Selector:       controller-uid=db30dd3f-8fce-11e9-9ec7-46b2371e9153\r\n",
      "Labels:         controller-uid=db30dd3f-8fce-11e9-9ec7-46b2371e9153\r\n",
      "                job-name=ad37cfbb9d1307a9-1560645420\r\n",
      "Annotations:    <none>\r\n",
      "Parallelism:    1\r\n",
      "Completions:    1\r\n",
      "Start Time:     Sat, 15 Jun 2019 20:37:01 -0400\r\n",
      "Completed At:   Sat, 15 Jun 2019 20:38:51 -0400\r\n",
      "Duration:       110s\r\n",
      "Pods Statuses:  0 Running / 1 Succeeded / 0 Failed\r\n",
      "Pod Template:\r\n",
      "  Labels:           controller-uid=db30dd3f-8fce-11e9-9ec7-46b2371e9153\r\n",
      "                    job-name=ad37cfbb9d1307a9-1560645420\r\n",
      "  Service Account:  metrics-collector\r\n",
      "  Containers:\r\n",
      "   ad37cfbb9d1307a9:\r\n",
      "    Image:      gcr.io/kubeflow-images-public/katib/metrics-collector:v0.1.2-alpha-156-g4ab3dbd\r\n",
      "    Port:       <none>\r\n",
      "    Host Port:  <none>\r\n",
      "    Args:\r\n",
      "      ./metricscollector\r\n",
      "      -s\r\n",
      "      sb3123f2df3038dc\r\n",
      "      -t\r\n",
      "      g3cb546f948e8801\r\n",
      "      -w\r\n",
      "      ad37cfbb9d1307a9\r\n",
      "      -k\r\n",
      "      Job\r\n",
      "      -n\r\n",
      "      kubeflow\r\n",
      "      -m\r\n",
      "      vizier-core.kubeflow:6789\r\n",
      "    Environment:  <none>\r\n",
      "    Mounts:       <none>\r\n",
      "  Volumes:        <none>\r\n",
      "Events:\r\n",
      "  Type    Reason            Age   From            Message\r\n",
      "  ----    ------            ----  ----            -------\r\n",
      "  Normal  SuccessfulCreate  18m   job-controller  Created pod: ad37cfbb9d1307a9-1560645420-fncjh\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl describe job ad37cfbb9d1307a9-1560645420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best run and printout metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now evaluate the metrics on the test data. To do this, get the SVD model that was saved as model.dump in the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = surprise.dump.load('aml_model/model.dump')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 1.0331492610799313, 'precision_at_k': 0.09968017057569298, 'ndcg_at_k': 0.1160964958978592}\n"
     ]
    }
   ],
   "source": [
    "test_results = {}\n",
    "predictions = compute_rating_predictions(svd, test, usercol=USERCOL, itemcol=ITEMCOL)\n",
    "for metric in RATING_METRICS:\n",
    "    test_results[metric] = eval(metric)(test, predictions)\n",
    "\n",
    "all_predictions = compute_ranking_predictions(svd, train, usercol=USERCOL, itemcol=ITEMCOL, recommend_seen=RECOMMEND_SEEN)\n",
    "for metric in RANKING_METRICS:\n",
    "    test_results[metric] = eval(metric)(test, all_predictions, col_prediction='prediction', k=K)\n",
    "\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Concluding Remarks\n",
    "\n",
    "We showed how to tune **all** the hyperparameters accepted by Surprise SVD simultaneously, by utilizing Kubeflow on AKS.\n",
    "\n",
    "TODO add insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup\n",
    "\n",
    "To uninstall Kubeflow,\n",
    "```\n",
    "cd ${KF_APP}\n",
    "# If you want to delete all the resources, including storage.\n",
    "kfctl delete all --delete_storage\n",
    "# If you want to preserve storage, which contains metadata and information\n",
    "# from mlpipeline.\n",
    "kfctl delete all\n",
    "```\n",
    "\n",
    "To remove AKS cluster,\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reco_base",
   "language": "python",
   "name": "reco_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
